{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c2652b1-6eec-45d2-bc68-41f2a5b7c97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000005.jpg 263 211 324 339 8 165 264 253 372 8 5 244 67 374 8 241 194 295 299 8 277 186 312 220 8\n",
      "000007.jpg 141 50 500 330 6\n",
      "000009.jpg 69 172 270 330 12 150 141 229 284 14 285 201 327 331 14 258 198 297 329 14\n",
      "000012.jpg 156 97 351 270 6\n",
      "000016.jpg 92 72 305 473 1\n",
      "000017.jpg 185 62 279 199 14 90 78 403 336 12\n"
     ]
    }
   ],
   "source": [
    "classes_name =  [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \n",
    "                 \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \n",
    "                 \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \n",
    "                 \"sheep\", \"sofa\", \"train\",\"tvmonitor\"]\n",
    "\n",
    "training_data_file = open(\"./2024-datalab-cup2-object-detection/2024-datalab-cup2-object-detection/pascal_voc_training_data.txt\", \"r\")\n",
    "for i, line in enumerate(training_data_file):\n",
    "    if i >5:\n",
    "        break\n",
    "    line = line.strip()\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2abf4e2-cade-4ed4-a1ac-c479d32528f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 13:55:13.663171: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-11 13:55:14.240349: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 13:55:14.899854: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-11 13:55:14.900058: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-11 13:55:14.905661: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-11 13:55:14.905834: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-11 13:55:14.905978: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-11 13:55:14.906117: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-11 13:55:14.907062: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-11 13:55:14.907326: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-11 13:55:14.907467: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-11 13:55:15.366476: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-11 13:55:15.366656: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-11 13:55:15.366802: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-11 13:55:15.366925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9637 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        # Select GPU number 1\n",
    "        tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9c08e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# common params\n",
    "IMAGE_SIZE = 448\n",
    "BATCH_SIZE = 8\n",
    "NUM_CLASSES = 20\n",
    "MAX_OBJECTS_PER_IMAGE = 20\n",
    "\n",
    "# dataset params\n",
    "DATA_PATH = '2024-datalab-cup2-object-detection/2024-datalab-cup2-object-detection/pascal_voc_training_data.txt'\n",
    "IMAGE_DIR = '2024-datalab-cup2-object-detection/2024-datalab-cup2-object-detection/VOCdevkit_train/VOC2007/JPEGImages/'\n",
    "\n",
    "# model params\n",
    "CELL_SIZE = 7\n",
    "BOXES_PER_CELL = 2\n",
    "OBJECT_SCALE = 1\n",
    "NOOBJECT_SCALE = 0.5\n",
    "CLASS_SCALE = 1\n",
    "COORD_SCALE = 5\n",
    "\n",
    "# training params\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1393b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetGenerator:\n",
    "    \"\"\"\n",
    "    Load pascalVOC 2007 dataset and creates an input pipeline.\n",
    "    - Reshapes images into 448 x 448\n",
    "    - converts [0 1] to [-1 1]\n",
    "    - shuffles the input\n",
    "    - builds batches\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.image_names = []\n",
    "        self.record_list = []\n",
    "        self.object_num_list = []\n",
    "        # filling the record_list\n",
    "        input_file = open(DATA_PATH, 'r')\n",
    "\n",
    "        for line in input_file:\n",
    "            line = line.strip()\n",
    "            ss = line.split(' ')\n",
    "            self.image_names.append(ss[0])\n",
    "\n",
    "            self.record_list.append([float(num) for num in ss[1:]])\n",
    "\n",
    "            self.object_num_list.append(min(len(self.record_list[-1])//5, \n",
    "                                            MAX_OBJECTS_PER_IMAGE))\n",
    "            if len(self.record_list[-1]) < MAX_OBJECTS_PER_IMAGE*5:\n",
    "                # if there are objects less than MAX_OBJECTS_PER_IMAGE, pad the list\n",
    "                self.record_list[-1] = self.record_list[-1] +\\\n",
    "                [0., 0., 0., 0., 0.]*\\\n",
    "                (MAX_OBJECTS_PER_IMAGE-len(self.record_list[-1])//5)\n",
    "                \n",
    "            elif len(self.record_list[-1]) > MAX_OBJECTS_PER_IMAGE*5:\n",
    "               # if there are objects more than MAX_OBJECTS_PER_IMAGE, crop the list\n",
    "                self.record_list[-1] = self.record_list[-1][:MAX_OBJECTS_PER_IMAGE*5]\n",
    "\n",
    "    def _data_preprocess(self, image_name, raw_labels, object_num):\n",
    "        image_file = tf.io.read_file(IMAGE_DIR+image_name)\n",
    "        image = tf.io.decode_jpeg(image_file, channels=3)\n",
    "\n",
    "        h = tf.shape(image)[0]\n",
    "        w = tf.shape(image)[1]\n",
    "\n",
    "        width_ratio  = IMAGE_SIZE * 1.0 / tf.cast(w, tf.float32) \n",
    "        height_ratio = IMAGE_SIZE * 1.0 / tf.cast(h, tf.float32) \n",
    "\n",
    "        image = tf.image.resize(image, size=[IMAGE_SIZE, IMAGE_SIZE])\n",
    "        image = (image/255) * 2 - 1\n",
    "\n",
    "        raw_labels = tf.cast(tf.reshape(raw_labels, [-1, 5]), tf.float32)\n",
    "\n",
    "        xmin = raw_labels[:, 0]\n",
    "        ymin = raw_labels[:, 1]\n",
    "        xmax = raw_labels[:, 2]\n",
    "        ymax = raw_labels[:, 3]\n",
    "        class_num = raw_labels[:, 4]\n",
    "\n",
    "        xcenter = (xmin + xmax) * 1.0 / 2.0 * width_ratio\n",
    "        ycenter = (ymin + ymax) * 1.0 / 2.0 * height_ratio\n",
    "\n",
    "        box_w = (xmax - xmin) * width_ratio\n",
    "        box_h = (ymax - ymin) * height_ratio\n",
    "\n",
    "        labels = tf.stack([xcenter, ycenter, box_w, box_h, class_num], axis=1)\n",
    "\n",
    "        return image, labels, tf.cast(object_num, tf.int32)\n",
    "\n",
    "    def generate(self):\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((self.image_names, \n",
    "                                                      np.array(self.record_list), \n",
    "                                                      np.array(self.object_num_list)))\n",
    "        dataset = dataset.shuffle(100000)\n",
    "        dataset = dataset.map(self._data_preprocess, \n",
    "                              num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
    "        dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "        dataset = dataset.prefetch(buffer_size=200)\n",
    "\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72128417",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c05d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_leaky_relu(inputs, filters, size, stride):\n",
    "    x = layers.Conv2D(filters, size, stride, padding=\"same\",\n",
    "                      kernel_initializer=tf.keras.initializers.TruncatedNormal())(inputs)\n",
    "    x = layers.LeakyReLU(0.1)(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41a96151",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_inputs = keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "x = conv_leaky_relu(img_inputs, 64, 7, 2)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = conv_leaky_relu(x, 192, 3, 1)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = conv_leaky_relu(x, 128, 1, 1)\n",
    "x = conv_leaky_relu(x, 256, 3, 1)\n",
    "x = conv_leaky_relu(x, 256, 1, 1)\n",
    "x = conv_leaky_relu(x, 512, 3, 1)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = conv_leaky_relu(x, 256, 1, 1)\n",
    "x = conv_leaky_relu(x, 512, 3, 1)\n",
    "x = conv_leaky_relu(x, 256, 1, 1)\n",
    "x = conv_leaky_relu(x, 512, 3, 1)\n",
    "x = conv_leaky_relu(x, 256, 1, 1)\n",
    "x = conv_leaky_relu(x, 512, 3, 1)\n",
    "x = conv_leaky_relu(x, 256, 1, 1)\n",
    "x = conv_leaky_relu(x, 512, 3, 1)\n",
    "x = conv_leaky_relu(x, 512, 1, 1)\n",
    "x = conv_leaky_relu(x, 1024, 3, 1)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = conv_leaky_relu(x, 512, 1, 1)\n",
    "x = conv_leaky_relu(x, 1024, 3, 1)\n",
    "x = conv_leaky_relu(x, 512, 1, 1)\n",
    "x = conv_leaky_relu(x, 1024, 3, 1)\n",
    "x = conv_leaky_relu(x, 1024, 3, 1)\n",
    "x = conv_leaky_relu(x, 1024, 3, 2)\n",
    "x = conv_leaky_relu(x, 1024, 3, 1)\n",
    "x = conv_leaky_relu(x, 1024, 3, 1)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(4096, \n",
    "                 kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01))(x)\n",
    "x = layers.LeakyReLU(0.1)(x)\n",
    "outputs = layers.Dense(1470, \n",
    "                       kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01))(x)\n",
    "\n",
    "YOLO = keras.Model(inputs=img_inputs, outputs=outputs, name=\"YOLO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffe9fa85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"YOLO\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 448, 448, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 224, 224, 64)      9472      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 224, 224, 64)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 112, 112, 64)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 112, 112, 192)     110784    \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 112, 112, 192)     0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 56, 56, 192)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 56, 56, 128)       24704     \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 56, 56, 256)       0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 56, 56, 256)       65792     \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 56, 56, 256)       0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 56, 56, 512)       1180160   \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 56, 56, 512)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 28, 28, 512)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 28, 28, 256)       131328    \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 28, 28, 512)       0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 28, 28, 256)       131328    \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 28, 28, 512)       0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 28, 28, 256)       131328    \n",
      "                                                                 \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 28, 28, 512)       0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 28, 28, 256)       131328    \n",
      "                                                                 \n",
      " leaky_re_lu_12 (LeakyReLU)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " leaky_re_lu_13 (LeakyReLU)  (None, 28, 28, 512)       0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 28, 28, 512)       262656    \n",
      "                                                                 \n",
      " leaky_re_lu_14 (LeakyReLU)  (None, 28, 28, 512)       0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 28, 28, 1024)      4719616   \n",
      "                                                                 \n",
      " leaky_re_lu_15 (LeakyReLU)  (None, 28, 28, 1024)      0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 14, 14, 1024)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 14, 14, 512)       524800    \n",
      "                                                                 \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 14, 14, 1024)      4719616   \n",
      "                                                                 \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 14, 14, 1024)      0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 14, 14, 512)       524800    \n",
      "                                                                 \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 14, 14, 1024)      4719616   \n",
      "                                                                 \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 14, 14, 1024)      0         \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 14, 14, 1024)      9438208   \n",
      "                                                                 \n",
      " leaky_re_lu_20 (LeakyReLU)  (None, 14, 14, 1024)      0         \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 7, 7, 1024)        9438208   \n",
      "                                                                 \n",
      " leaky_re_lu_21 (LeakyReLU)  (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 7, 7, 1024)        9438208   \n",
      "                                                                 \n",
      " leaky_re_lu_22 (LeakyReLU)  (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 7, 7, 1024)        9438208   \n",
      "                                                                 \n",
      " leaky_re_lu_23 (LeakyReLU)  (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 50176)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              205524992 \n",
      "                                                                 \n",
      " leaky_re_lu_24 (LeakyReLU)  (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1470)              6022590   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 271703550 (1.01 GB)\n",
      "Trainable params: 271703550 (1.01 GB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "YOLO.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da109339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base boxes (for loss calculation)\n",
    "base_boxes = np.zeros([CELL_SIZE, CELL_SIZE, 4])\n",
    "\n",
    "# initializtion for each cell\n",
    "for y in range(CELL_SIZE):\n",
    "    for x in range(CELL_SIZE):\n",
    "        base_boxes[y, x, :] = [IMAGE_SIZE / CELL_SIZE * x, \n",
    "                               IMAGE_SIZE / CELL_SIZE * y, 0, 0]\n",
    "\n",
    "base_boxes = np.resize(base_boxes, [CELL_SIZE, CELL_SIZE, 1, 4])\n",
    "base_boxes = np.tile(base_boxes, [1, 1, BOXES_PER_CELL, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e29d509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_loss(predicts, labels, objects_num):\n",
    "    \"\"\"\n",
    "    Add Loss to all the trainable variables\n",
    "    Args:\n",
    "        predicts: 4-D tensor [batch_size, cell_size, cell_size, num_classes + 5 * boxes_per_cell]\n",
    "        ===> (num_classes, boxes_per_cell, 4 * boxes_per_cell)\n",
    "        labels  : 3-D tensor of [batch_size, max_objects, 5]\n",
    "        objects_num: 1-D tensor [batch_size]\n",
    "    \"\"\"\n",
    "\n",
    "    loss = 0.\n",
    "    \n",
    "    #you can parallel the code with tf.map_fn or tf.vectorized_map (big performance gain!)\n",
    "    for i in tf.range(BATCH_SIZE):\n",
    "        predict = predicts[i, :, :, :]\n",
    "        label = labels[i, :, :]\n",
    "        object_num = objects_num[i]\n",
    "\n",
    "        for j in tf.range(object_num):\n",
    "            results = losses_calculation(predict, label[j:j+1, :])\n",
    "            loss = loss + results\n",
    "\n",
    "    return loss/BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aec7d2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(boxes1, boxes2):\n",
    "    \"\"\"calculate ious\n",
    "    Args:\n",
    "      boxes1: 4-D tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4]  ====> (x_center, y_center, w, h)\n",
    "      boxes2: 1-D tensor [4] ===> (x_center, y_center, w, h)\n",
    "\n",
    "    Return:\n",
    "      iou: 3-D tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "      ====> iou score for each cell\n",
    "    \"\"\"\n",
    "\n",
    "    #boxes1 : [4(xmin, ymin, xmax, ymax), cell_size, cell_size, boxes_per_cell]\n",
    "    boxes1 = tf.stack([boxes1[:, :, :, 0] - boxes1[:, :, :, 2] / 2, boxes1[:, :, :, 1] - boxes1[:, :, :, 3] / 2,\n",
    "                      boxes1[:, :, :, 0] + boxes1[:, :, :, 2] / 2, boxes1[:, :, :, 1] + boxes1[:, :, :, 3] / 2])\n",
    "\n",
    "    #boxes1 : [cell_size, cell_size, boxes_per_cell, 4(xmin, ymin, xmax, ymax)]\n",
    "    boxes1 = tf.transpose(boxes1, [1, 2, 3, 0])\n",
    "\n",
    "    boxes2 =  tf.stack([boxes2[0] - boxes2[2] / 2, boxes2[1] - boxes2[3] / 2,\n",
    "                      boxes2[0] + boxes2[2] / 2, boxes2[1] + boxes2[3] / 2])\n",
    "\n",
    "    #calculate the left up point of boxes' overlap area\n",
    "    lu = tf.maximum(boxes1[:, :, :, 0:2], boxes2[0:2])\n",
    "    #calculate the right down point of boxes overlap area\n",
    "    rd = tf.minimum(boxes1[:, :, :, 2:], boxes2[2:])\n",
    "\n",
    "    #intersection\n",
    "    intersection = rd - lu \n",
    "\n",
    "    #the size of the intersection area\n",
    "    inter_square = intersection[:, :, :, 0] * intersection[:, :, :, 1]\n",
    "\n",
    "    mask = tf.cast(intersection[:, :, :, 0] > 0, tf.float32) * tf.cast(intersection[:, :, :, 1] > 0, tf.float32)\n",
    "\n",
    "    #if intersection is negative, then the boxes don't overlap\n",
    "    inter_square = mask * inter_square\n",
    "\n",
    "    #calculate the boxs1 square and boxs2 square\n",
    "    square1 = (boxes1[:, :, :, 2] - boxes1[:, :, :, 0]) * (boxes1[:, :, :, 3] - boxes1[:, :, :, 1])\n",
    "    square2 = (boxes2[2] - boxes2[0]) * (boxes2[3] - boxes2[1])\n",
    "\n",
    "    return inter_square/(square1 + square2 - inter_square + 1e-6)\n",
    "\n",
    "def losses_calculation(predict, label):\n",
    "    \"\"\"\n",
    "    calculate loss\n",
    "    Args:\n",
    "      predict: 3-D tensor [cell_size, cell_size, num_classes + 5 * boxes_per_cell]\n",
    "      label : [1, 5]  (x_center, y_center, w, h, class)\n",
    "    \"\"\"\n",
    "    label = tf.reshape(label, [-1])\n",
    "\n",
    "    #Step A. calculate objects tensor [CELL_SIZE, CELL_SIZE]\n",
    "    #turn pixel position into cell position (corner)\n",
    "    min_x = (label[0] - label[2] / 2) / (IMAGE_SIZE / CELL_SIZE)\n",
    "    max_x = (label[0] + label[2] / 2) / (IMAGE_SIZE / CELL_SIZE)\n",
    "\n",
    "    min_y = (label[1] - label[3] / 2) / (IMAGE_SIZE / CELL_SIZE)\n",
    "    max_y = (label[1] + label[3] / 2) / (IMAGE_SIZE / CELL_SIZE)\n",
    "\n",
    "    min_x = tf.floor(min_x)\n",
    "    min_y = tf.floor(min_y)\n",
    "\n",
    "    max_x = tf.minimum(tf.math.ceil(max_x), CELL_SIZE)\n",
    "    max_y = tf.minimum(tf.math.ceil(max_y), CELL_SIZE)\n",
    "    \n",
    "    #calculate mask of object with cells\n",
    "    onset = tf.cast(tf.stack([max_y - min_y, max_x - min_x]), dtype=tf.int32)\n",
    "    object_mask = tf.ones(onset, tf.float32)\n",
    "\n",
    "    offset = tf.cast(tf.stack([min_y, CELL_SIZE - max_y, min_x, CELL_SIZE - max_x]), tf.int32)\n",
    "    offset = tf.reshape(offset, (2, 2))\n",
    "    object_mask = tf.pad(object_mask, offset, \"CONSTANT\")\n",
    "\n",
    "    #Step B. calculate the coordination of object center and the corresponding mask\n",
    "    #turn pixel position into cell position (center)\n",
    "    center_x = label[0] / (IMAGE_SIZE / CELL_SIZE)\n",
    "    center_x = tf.floor(center_x)\n",
    "\n",
    "    center_y = label[1] / (IMAGE_SIZE / CELL_SIZE)\n",
    "    center_y = tf.floor(center_y)\n",
    "\n",
    "    response = tf.ones([1, 1], tf.float32)\n",
    "\n",
    "    #calculate the coordination of object center with cells\n",
    "    objects_center_coord = tf.cast(tf.stack([center_y, CELL_SIZE - center_y - 1, \n",
    "                             center_x, CELL_SIZE - center_x - 1]), \n",
    "                             tf.int32)\n",
    "    objects_center_coord = tf.reshape(objects_center_coord, (2, 2))\n",
    "\n",
    "    #make mask\n",
    "    response = tf.pad(response, objects_center_coord, \"CONSTANT\")\n",
    "\n",
    "    #Step C. calculate iou_predict_truth [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    predict_boxes = predict[:, :, NUM_CLASSES + BOXES_PER_CELL:]\n",
    "\n",
    "    predict_boxes = tf.reshape(predict_boxes, [CELL_SIZE, \n",
    "                                               CELL_SIZE, \n",
    "                                               BOXES_PER_CELL, 4])\n",
    "    #cell position to pixel position\n",
    "    predict_boxes = predict_boxes * [IMAGE_SIZE / CELL_SIZE, \n",
    "                                     IMAGE_SIZE / CELL_SIZE, \n",
    "                                     IMAGE_SIZE, IMAGE_SIZE]\n",
    "\n",
    "    #if there's no predict_box in that cell, then the base_boxes will be calcuated with label and got iou equals 0\n",
    "    predict_boxes = base_boxes + predict_boxes\n",
    "\n",
    "    iou_predict_truth = iou(predict_boxes, label[0:4])\n",
    "\n",
    "    #calculate C tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    C = iou_predict_truth * tf.reshape(response, [CELL_SIZE, CELL_SIZE, 1])\n",
    "\n",
    "    #calculate I tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    I = iou_predict_truth * tf.reshape(response, [CELL_SIZE, CELL_SIZE, 1])\n",
    "\n",
    "    max_I = tf.reduce_max(I, 2, keepdims=True)\n",
    "\n",
    "    #replace large iou scores with response (object center) value\n",
    "    I = tf.cast((I >= max_I), tf.float32) * tf.reshape(response, (CELL_SIZE, CELL_SIZE, 1))\n",
    "\n",
    "    #calculate no_I tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    no_I = tf.ones_like(I, dtype=tf.float32) - I\n",
    "\n",
    "    p_C = predict[:, :, NUM_CLASSES:NUM_CLASSES + BOXES_PER_CELL]\n",
    "\n",
    "    #calculate truth x, y, sqrt_w, sqrt_h 0-D\n",
    "    x = label[0]\n",
    "    y = label[1]\n",
    "\n",
    "    sqrt_w = tf.sqrt(tf.abs(label[2]))\n",
    "    sqrt_h = tf.sqrt(tf.abs(label[3]))\n",
    "\n",
    "    #calculate predict p_x, p_y, p_sqrt_w, p_sqrt_h 3-D [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    p_x = predict_boxes[:, :, :, 0]\n",
    "    p_y = predict_boxes[:, :, :, 1]\n",
    "\n",
    "    p_sqrt_w = tf.sqrt(tf.minimum(IMAGE_SIZE * 1.0, tf.maximum(0.0, predict_boxes[:, :, :, 2])))\n",
    "    p_sqrt_h = tf.sqrt(tf.minimum(IMAGE_SIZE * 1.0, tf.maximum(0.0, predict_boxes[:, :, :, 3])))\n",
    "\n",
    "    #calculate ground truth p 1-D tensor [NUM_CLASSES]\n",
    "    P = tf.one_hot(tf.cast(label[4], tf.int32), NUM_CLASSES, dtype=tf.float32)\n",
    "\n",
    "    #calculate predicted p_P 3-D tensor [CELL_SIZE, CELL_SIZE, NUM_CLASSES]\n",
    "    p_P = predict[:, :, 0:NUM_CLASSES]\n",
    "\n",
    "    #class_loss\n",
    "    class_loss = tf.nn.l2_loss(tf.reshape(object_mask, (CELL_SIZE, CELL_SIZE, 1)) * (p_P - P)) * CLASS_SCALE\n",
    "\n",
    "    #object_loss\n",
    "    object_loss = tf.nn.l2_loss(I * (p_C - C)) * OBJECT_SCALE\n",
    "\n",
    "    #noobject_loss\n",
    "    noobject_loss = tf.nn.l2_loss(no_I * (p_C)) * NOOBJECT_SCALE\n",
    "\n",
    "    #coord_loss\n",
    "    coord_loss = (tf.nn.l2_loss(I * (p_x - x)/(IMAGE_SIZE/CELL_SIZE)) +\n",
    "                  tf.nn.l2_loss(I * (p_y - y)/(IMAGE_SIZE/CELL_SIZE)) +\n",
    "                  tf.nn.l2_loss(I * (p_sqrt_w - sqrt_w))/IMAGE_SIZE +\n",
    "                  tf.nn.l2_loss(I * (p_sqrt_h - sqrt_h))/IMAGE_SIZE) * COORD_SCALE\n",
    "\n",
    "    return class_loss + object_loss + noobject_loss + coord_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44311ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_PrefetchDataset element_spec=(TensorSpec(shape=(8, 448, 448, 3), dtype=tf.float32, name=None), TensorSpec(shape=(8, 20, 5), dtype=tf.float32, name=None), TensorSpec(shape=(8,), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "dataset = DatasetGenerator().generate()\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42395f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
    "train_loss_metric = tf.keras.metrics.Mean(name='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9345d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = tf.Variable(0, name='epoch', trainable=False)\n",
    "ckpt = tf.train.Checkpoint(epoch=tf.Variable(0), net=YOLO)\n",
    "manager = tf.train.CheckpointManager(ckpt, './ckpts/YOLO', max_to_keep=3,\n",
    "                                     checkpoint_name='yolo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aea634a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(image, labels, objects_num):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = YOLO(image)\n",
    "        class_end = CELL_SIZE * CELL_SIZE * NUM_CLASSES\n",
    "        conf_end = class_end + CELL_SIZE * CELL_SIZE * BOXES_PER_CELL\n",
    "        class_probs = tf.reshape(outputs[:, 0:class_end], (-1, 7, 7, 20))\n",
    "        confs = tf.reshape(outputs[:, class_end:conf_end], (-1, 7, 7, 2))\n",
    "        boxes = tf.reshape(outputs[:, conf_end:], (-1, 7, 7, 2*4))\n",
    "        predicts = tf.concat([class_probs, confs, boxes], 3)\n",
    "\n",
    "        loss = yolo_loss(predicts, labels, objects_num)\n",
    "        train_loss_metric(loss)\n",
    "\n",
    "    grads = tape.gradient(loss, YOLO.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, YOLO.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7781494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-08 13:56:36.814850, start training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 13:56:42.810923: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8905\n",
      "2024-11-08 13:56:42.931581: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-11-08 13:56:43.345713: W tensorflow/tsl/framework/bfc_allocator.cc:366] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2024-11-08 13:56:44.045666: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.33GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-11-08 13:56:44.108553: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.33GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-11-08 13:56:44.173608: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.33GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-11-08 13:56:44.383541: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.35GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-11-08 13:56:44.418449: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.29GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-11-08 13:56:44.654024: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-11-08 13:56:44.677817: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.19GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-11-08 13:56:45.004426: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc6c4523a90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-11-08 13:56:45.004443: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2024-11-08 13:56:45.007580: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-08 13:56:45.067398: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-11-08 13:56:45.111872: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-08 13:58:21.711924, Epoch 1: loss 827.81\n",
      "Saved checkpoint for epoch 1: ./ckpts/YOLO/yolo-1\n",
      "2024-11-08 13:59:58.341710, Epoch 2: loss 20.85\n",
      "Saved checkpoint for epoch 2: ./ckpts/YOLO/yolo-2\n",
      "2024-11-08 14:01:35.303099, Epoch 3: loss 20.44\n",
      "Saved checkpoint for epoch 3: ./ckpts/YOLO/yolo-3\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "print(\"{}, start training.\".format(datetime.now()))\n",
    "for i in range(EPOCHS):\n",
    "    train_loss_metric.reset_states()\n",
    "    ckpt.epoch.assign_add(1)\n",
    "\n",
    "    for idx, (image, labels, objects_num) in enumerate(dataset):\n",
    "        train_step(image, labels, objects_num)\n",
    "\n",
    "    print(\"{}, Epoch {}: loss {:.2f}\".format(datetime.now(), i+1, train_loss_metric.result()))\n",
    "\n",
    "    save_path = manager.save()\n",
    "    print(\"Saved checkpoint for epoch {}: {}\".format(int(ckpt.epoch), save_path))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "661cc69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_outputs(outputs):\n",
    "    \"\"\"\n",
    "    Process YOLO outputs into bou\n",
    "    \"\"\"\n",
    "\n",
    "    class_end = CELL_SIZE * CELL_SIZE * NUM_CLASSES\n",
    "    conf_end = class_end + CELL_SIZE * CELL_SIZE * BOXES_PER_CELL\n",
    "    class_probs = np.reshape(outputs[:, 0:class_end], (-1, 7, 7, 20))\n",
    "    confs = np.reshape(outputs[:, class_end:conf_end], (-1, 7, 7, 2))\n",
    "    boxes = np.reshape(outputs[:, conf_end:], (-1, 7, 7, 2*4))\n",
    "    predicts = np.concatenate([class_probs, confs, boxes], 3)\n",
    "\n",
    "    p_classes = predicts[0, :, :, 0:20]\n",
    "    C = predicts[0, :, :, 20:22]\n",
    "    coordinate = predicts[0, :, :, 22:]\n",
    "\n",
    "    p_classes = np.reshape(p_classes, (CELL_SIZE, CELL_SIZE, 1, 20))\n",
    "    C = np.reshape(C, (CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 1))\n",
    "\n",
    "    P = C * p_classes\n",
    "    #P's shape [7, 7, 2, 20]\n",
    "\n",
    "    #choose the most confidence one\n",
    "    max_conf = np.max(P)\n",
    "    index = np.argmax(P)\n",
    "\n",
    "    index = np.unravel_index(index, P.shape)\n",
    "\n",
    "    class_num = index[3]\n",
    "\n",
    "    coordinate = np.reshape(coordinate, \n",
    "                            (CELL_SIZE, \n",
    "                             CELL_SIZE,\n",
    "                             BOXES_PER_CELL, \n",
    "                             4))\n",
    "\n",
    "    max_coordinate = coordinate[index[0], index[1], index[2], :]\n",
    "\n",
    "    xcenter = max_coordinate[0]\n",
    "    ycenter = max_coordinate[1]\n",
    "    w = max_coordinate[2]\n",
    "    h = max_coordinate[3]\n",
    "\n",
    "    xcenter = (index[1] + xcenter) * (IMAGE_SIZE/float(CELL_SIZE))\n",
    "    ycenter = (index[0] + ycenter) * (IMAGE_SIZE/float(CELL_SIZE))\n",
    "\n",
    "    w = w * IMAGE_SIZE\n",
    "    h = h * IMAGE_SIZE\n",
    "\n",
    "    xmin = xcenter - w/2.0\n",
    "    ymin = ycenter - h/2.0\n",
    "\n",
    "    xmax = xmin + w\n",
    "    ymax = ymin + h\n",
    "\n",
    "    return xmin, ymin, xmax, ymax, class_num, max_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd2a1125",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_files = open('2024-datalab-cup2-object-detection/2024-datalab-cup2-object-detection/pascal_voc_testing_data.txt')\n",
    "test_img_dir = '2024-datalab-cup2-object-detection/2024-datalab-cup2-object-detection/VOCdevkit_test/VOC2007/JPEGImages/'\n",
    "test_images = []\n",
    "\n",
    "for line in test_img_files:\n",
    "    line = line.strip()\n",
    "    ss = line.split(' ')\n",
    "    test_images.append(ss[0])\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_images)\n",
    "\n",
    "def load_img_data(image_name):\n",
    "    image_file = tf.io.read_file(test_img_dir+image_name)\n",
    "    image = tf.image.decode_jpeg(image_file, channels=3)\n",
    "\n",
    "    h = tf.shape(image)[0]\n",
    "    w = tf.shape(image)[1]\n",
    "\n",
    "    image = tf.image.resize(image, size=[IMAGE_SIZE, IMAGE_SIZE])\n",
    "    image = (image/255) * 2 - 1\n",
    "\n",
    "    return image_name, image, h, w\n",
    "\n",
    "test_dataset = test_dataset.map(load_img_data, num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48b62490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f5d70280160>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = tf.train.Checkpoint(net=YOLO)\n",
    "ckpt.restore('./ckpts/YOLO/yolo-3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "056ce3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def prediction_step(img):\n",
    "    return YOLO(img, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d285065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 14:30:20.038109: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8905\n",
      "2024-11-08 14:30:20.093496: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "output_file = open('./test_prediction.txt', 'w')\n",
    "\n",
    "for img_name, test_img, img_h, img_w in test_dataset:\n",
    "    batch_num = img_name.shape[0]\n",
    "    for i in range(batch_num):\n",
    "        xmin, ymin, xmax, ymax, class_num, conf = process_outputs(prediction_step(test_img[i:i+1]))\n",
    "        xmin, ymin, xmax, ymax = xmin*(img_w[i:i+1]/IMAGE_SIZE), ymin*(img_h[i:i+1]/IMAGE_SIZE), xmax*(img_w[i:i+1]/IMAGE_SIZE), ymax*(img_h[i:i+1]/IMAGE_SIZE)\n",
    "\n",
    "        #img filename, xmin, ymin, xmax, ymax, class, confidence\n",
    "        output_file.write(img_name[i:i+1].numpy()[0].decode('ascii')+\" %d %d %d %d %d %f\\n\" %(xmin, ymin, xmax, ymax, class_num, conf))\n",
    "\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e913407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './evaluate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9efd2185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Evalutation\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "#evaluate.evaluate(\"input prediction file name\", \"desire output csv file name\")\n",
    "evaluate.evaluate('./test_prediction.txt', './output_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3c34112",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d929d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'IMAGE_SIZE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m np_img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2024-datalab-cup2-object-detection/2024-datalab-cup2-object-detection/VOCdevkit_test/VOC2007/JPEGImages/000002.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(np_img\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m----> 3\u001b[0m resized_img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(np_img, (\u001b[43mIMAGE_SIZE\u001b[49m, IMAGE_SIZE))\n\u001b[1;32m      4\u001b[0m np_img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(resized_img, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m      5\u001b[0m resized_img \u001b[38;5;241m=\u001b[39m np_img\n",
      "\u001b[0;31mNameError\u001b[0m: name 'IMAGE_SIZE' is not defined"
     ]
    }
   ],
   "source": [
    "np_img = cv2.imread('2024-datalab-cup2-object-detection/2024-datalab-cup2-object-detection/VOCdevkit_test/VOC2007/JPEGImages/000002.jpg')\n",
    "resized_img = cv2.resize(np_img, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "np_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
    "resized_img = np_img\n",
    "np_img = np_img.astype(np.float32)\n",
    "np_img = np_img / 255.0 * 2 - 1\n",
    "np_img = np.reshape(np_img, (1, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "y_pred = YOLO(np_img, training=False)\n",
    "xmin, ymin, xmax, ymax, class_num, conf = process_outputs(y_pred)\n",
    "class_name = classes_name[class_num]\n",
    "cv2.rectangle(resized_img, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (0, 255, 255), 3)\n",
    "cv2.putText(resized_img, class_name, (0, 200), 2, 1.5, (0, 255, 255), 2)\n",
    "\n",
    "plt.imshow(resized_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879b19c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_comp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
